## 高性能异步爬虫

目的： 在爬虫中使用异步实现高性能的数据爬取操作



## 异步爬虫的方式

* 多线程、多进程（不建议）
  * 好处： 可以为相关阻塞的操作单独开启线程或者进程，这些阻塞操作就可以异步执行。
  * 弊端： 无法无限制的开启多线程或者多进程。

* 线程池、进程池（适当使用）：
  * 好处：我们可以降低系统对进程或线程创建和销毁的一个频率。
  * 弊端：池中线程或线程的数量是有上限的

## 例子

单线程串行的方式

```python
import time


def get_page(url):
    print("正在下载", url)
    time.sleep(2)
    print("下载成功", url)


name_list = ['a', 'b', 'c', 'd']

start_time = time.time()

for obj in name_list:
    get_page(obj)

end_time = time.time()

print("%d second" % (end_time - start_time))

```

使用线程池

```python
import time
from multiprocessing.dummy import Pool

start_time = time.time()


def get_page(url):
    print("正在下载", url)
    time.sleep(2)
    print("下载成功", url)


name_list = ['a', 'b', 'c', 'd']

pool = Pool(4)
# 将列表中每个列表元素传递给get_page
pool.map(get_page, name_list)

end_time = time.time()

print("%d second" % (end_time - start_time))

```

* 单线程+异步协程（推荐）
  * event_loop: 事件循环，相当于无线循环，我们可以把一些函数注册到这个事件循环上，当满足某些条件的时候，函数就会被循环执行
  * coroutine： 协程对象，我们可以将协程对象注册到事件循环中，它会被事件循环调用。我们可以使用async 关键字定义一个方法，这个方法可以在调用时不会立即被执行，而是返回一个协程对象。
  * task： 任务，它是对协程对象的进一步封装，它包含了任务的各个状态。
  * future：代表将来执行或还没有执行的任务，实际上没有本质的区别。
  * async 定义一个协程。
  * await 用来挂起阻塞方法的执行。



```python
import asyncio


async def requent(url):
    print("请求的url:", url)
    print("请求成功", url)
    return url


# 返回协程对象
c = requent("www.baidu.com")


# # 创建一个事件循环对象
# loop = asyncio.get_event_loop()
#
# # 将协程对象注册到loop中 启动loop
# loop.run_until_complete(c)

# task的使用
# loop = asyncio.get_event_loop()
# # 基于loop创建一个task
# task = loop.create_task(c)
# print(task)
#
# loop.run_until_complete(task)
#
# print(task)

# future的使用
# loop = asyncio.get_event_loop()
# task = asyncio.ensure_future(c)
# loop.run_until_complete(task)


# 事件绑定
def callback_func(tack):
    # result返回的就是任务对象中封装的协程对象对应函数的返回值
    print(tack.result())


loop = asyncio.get_event_loop()
task = asyncio.ensure_future(c)
# 将回调函数绑定到任务对象中
task.add_done_callback(callback_func)
loop.run_until_complete(task)


```

## 多任务协程

内容都在代码里

```python
import asyncio
import time


async def request(url):
    print("正在下载", url)
    # 在异步协程中如果出现了同步模块相关的代码，那就无法实现异步
    # time.sleep(2)
    # 当在asyncio中遇到阻塞操作必须手动挂起
    await asyncio.sleep(2)
    print("下载成功", url)
    return url

start_time = time.time()
urls = [
    "www.baidu.com",
    "www.sogou.com",
    "www.goubanjia.com"
]

# 任务列表
tasks = []
for url in urls:
    c = request(url)
    task = asyncio.ensure_future(c)
    tasks.append(task)

loop = asyncio.get_event_loop()
# 需要将任务列表封装到wait中
loop.run_until_complete(asyncio.wait(tasks))

end_time = time.time()

print("%d second" % (end_time - start_time))

```

异步网络请求aiohttp模块

```python
async def get_page(url):
    async with aiohttp.ClientSession() as session:
        async with await session.get(url) as response:
            # text() 返回字符串形式的响应数据
            # read() 返回二进制
            # json() 返回json
            # 注： 在获取响应数据之前一定要手动用await挂起
            page_text = await response.text()
            print(page_text)
    
```



